{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 4 \n",
    "\n",
    "February 24, 2025\n",
    "\n",
    "# Outline\n",
    "\n",
    "# 1. Recap of Numpy arrays\n",
    "\n",
    "# 2. Practice with Example\n",
    "\n",
    "# 3. Saving Numpy arrays to files\n",
    "\n",
    "# 4. Quiz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Recap NumPy Arrays\n",
    "\n",
    "## 1. Performance (Speed)\n",
    "- NumPy arrays are much **faster** than Python lists because they are implemented in C and use contiguous memory allocation.\n",
    "- Operations on NumPy arrays are optimized and use vectorized computations, avoiding slow Python loops.\n",
    "- NumPy leverages efficient memory access patterns and CPU optimizations (e.g., SIMD instructions).\n",
    "\n",
    "## 2. Memory Efficiency\n",
    "- NumPy arrays consume **less memory** compared to Python lists because they store elements of the same data type in a contiguous block of memory.\n",
    "- Lists in Python store references to objects, adding overhead, whereas NumPy uses a compact data structure.\n",
    "\n",
    "## 3. Vectorization (Element-wise Operations)\n",
    "- NumPy allows **vectorized operations**, meaning mathematical operations are applied to entire arrays without explicit loops.\n",
    "- Example:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array([1, 2, 3, 4])\n",
    "b = np.array([10, 20, 30, 40])\n",
    "c = a + b  # [11, 22, 33, 44] (element-wise addition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In contrast, a Python list would require a loop or list comprehension.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addition(x, y):\n",
    "    return x+y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer, float variables\n",
    "\n",
    "k, l = 10, 20\n",
    "k_plus_l = addition(k,l)\n",
    "print(k_plus_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list objects:\n",
    "la = [1, 2, 3]\n",
    "lb = [4, 5, 6]\n",
    "lsum = addition(la, lb)\n",
    "print(lsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy array\n",
    "a = np.array([1, 2, 3, 4])\n",
    "b = np.array([10, 20, 30, 40])\n",
    "a_plus_b = addition(a,b)\n",
    "print(a_plus_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_addition = np.vectorize(addition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_plus_b_v2 = vectorized_addition(a,b)\n",
    "print(a_plus_b_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import factorial\n",
    "\n",
    "def factorial_calculation( n):\n",
    "    return factorial(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(factorial_calculation(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(factorial_calculation(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_factorial = np.vectorize(factorial_calculation)\n",
    "\n",
    "print(vectorized_factorial(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Broadcasting\n",
    "- NumPy supports broadcasting, which allows operations between arrays of different shapes without explicit loops.\n",
    "- Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "b = 2  # Scalar\n",
    "c = a * b  # [2, 4, 6] (scalar is broadcasted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Built-in Mathematical and Statistical Functions\n",
    "- NumPy provides a rich set of mathematical functions (np.mean, np.sum, np.std, etc.).\n",
    "- Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "print(np.mean(arr))  # 3.0\n",
    "print(np.std(arr))   # 1.414...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Multidimensional Arrays & Matrix Operations\n",
    "- Unlike Python lists, NumPy supports multi-dimensional arrays (e.g., 2D matrices, 3D tensors).\n",
    "- Example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.array([[1, 2], [3, 4]])\n",
    "print(matrix.T)  # Transpose of the matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Interoperability with Other Libraries\n",
    "- NumPy is the foundation for many scientific computing and machine learning libraries, such as **Pandas, SciPy, TensorFlow, PyTorch**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Indexing and Slicing\n",
    "- NumPy arrays support advanced **indexing and slicing**, enabling efficient selection and manipulation of subsets of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Must-Know Operations\n",
    "\n",
    "| Operation          | Example                                      |\n",
    "|--------------------|----------------------------------------------|\n",
    "| **Creating arrays**  | `np.array([1,2,3])`, `np.zeros((3,3))`, `np.random.rand(3,3)` |\n",
    "| **Reshaping**       | `arr.reshape(3,3)`                         |\n",
    "| **Indexing & Slicing** | `arr[1, :]`, `arr[:, 1]`              |\n",
    "| **Math operations** | `arr + 2`, `np.dot(A, B)`, `A @ B`         |\n",
    "| **Aggregation**     | `np.mean(arr)`, `np.sum(arr, axis=0)`      |\n",
    "| **Boolean Indexing** | `arr[arr > 10]`                         |\n",
    "| **Stacking**        | `np.vstack((A,B))`, `np.hstack((A,B))`    |\n",
    "| **Broadcasting**    | `A + B` (different shapes)                |\n",
    "| **Linear Algebra**  | `np.linalg.inv(A)`, `np.linalg.eig(A)`     |\n",
    "| **File I/O**        | `np.loadtxt('data.csv', delimiter=',')`    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Practice\n",
    "- 1. Represent this data table with a numpy array\n",
    "- 2. Calculate GDP per capita and population density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| State      | Population (Million) | Area (Thousand sq mi) | GDP (Billion USD) |\n",
    "|------------|----------------------|-----------------------|-------------------|\n",
    "| California | 39.2                 | 163.7                 | 4,080.2          |\n",
    "| Texas      | 31.3                 | 268.6                 | 2,694.5          |\n",
    "| New York   | 19.0                 | 54.6                  | 2,284.4          |\n",
    "| Florida    | 22.0                 | 65.8                  | 1,695.3          |\n",
    "| Washington | 7.8                  | 71.3                  | 808.0            |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create a Numpy array representation of this data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data: [Population (Million), Area (Thousand sq mi), GDP (Billion USD)]\n",
    "data = np.array([\n",
    "    [39.2, 163.7, 4080.2],  # California\n",
    "    [31.3, 268.6, 2694.5],  # Texas\n",
    "    [19.0,  54.6, 2284.4],  # New York\n",
    "    [22.0,  65.8, 1695.3],  # Florida\n",
    "    [7.8,   71.3,  808.0]   # Washington\n",
    "])\n",
    "\n",
    "# Print the NumPy array\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Build a helper function to break down key info of a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's check basic information of this array\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def check_np(arr):\n",
    "    \"\"\"\n",
    "    Function to print the dimension, shape, and size of a NumPy array.\n",
    "    Raises an exception if the input is not a NumPy array.\n",
    "\n",
    "    Parameters:\n",
    "    arr (numpy.ndarray): The input NumPy array.\n",
    "    \"\"\"\n",
    "    if not isinstance(arr, np.ndarray):\n",
    "        raise TypeError(\"Input must be a NumPy array.\")\n",
    "\n",
    "    print(f\"Dimension: {arr.ndim}\")\n",
    "    print(f\"Shape: {arr.shape}\")\n",
    "    print(f\"Size: {arr.size}\")\n",
    "    print(f\"Array printout: \\n {arr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_np(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Calculate the ratio of GDP to Population with \"vectorized\" (element-wise) operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to calculate GDP per capita, which is defined as the GDP of a state divided by its population:\n",
    "\n",
    "#### **GDP per capita = GDP / Population**\n",
    "\n",
    "Using a NumPy array, I can retrieve an array containing the GDP values for all five states and another array containing their respective populations. By performing element-wise division of the GDP array by the population array, I obtain an array of GDP per capita values. Below is an example:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDP = data[:,2]\n",
    "population = data[:,0]\n",
    "GDP_per_capita = GDP / population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_np(GDP_per_capita)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Correct the unit by broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unit of these numbers are billion dollars per million people, which is not exactly \"per capita\". So we should convert these numbers to dollars per person. \n",
    "\n",
    "#### **GDP_per_capita_with_proper_unit = GDP_per_capita$\\times \\frac{10^9}{10^6}$**\n",
    "\n",
    "Because this factor is applied to all entries in the GDP_per_capita array, it will take advantage of the broadcasting capability of numpy array. What it means is that you only need to multiple this factor to the numpy array `GDP_per_capita` as a whole. There is no need to do it individually for each element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDP_per_capita_with_proper_unit = GDP_per_capita*(1e9)/(1e6)\n",
    "check_np(GDP_per_capita_with_proper_unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Do all of these in one line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Of course, you can do this entire operation in one go\n",
    "- there is no need to create intermediate arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDP_percapita = data[:,2]/data[:,0]*1e9/1e6\n",
    "check_np(GDP_percapita)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Add the per capita GDP back to the original numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### what needs to be done if I want to add this array `GDP_percapita` back to the original array `data`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_modified = np.hstack(data,GDP_percapita)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_modified = np.hstack(data,GDP_percapita)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6.1 Reshape the numpy array to the right shape\n",
    "- for hstack and vstack, the arrays to be merged must have the same dimension\n",
    "- for hstack, the size of axis 0 must be the same for two arrays\n",
    "- for vstack, the size of axis 1 must be the same for two arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDP_percapita = np.reshape(GDP_percapita, (5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_np(GDP_percapita)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_modified = np.hstack((data,GDP_percapita))\n",
    "check_np(data_modified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7.  Practice time: \n",
    "\n",
    " Can you follow the example to calculate the population density, which is defined as number of population per squared miles? Add this entry back to the `data_modified` array so that it has a shape of (5,5), corresponding to five states as rows (axis 0) and five quantities as columns (axis 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Saving numpy arrays\n",
    "\n",
    "There are a number of ways of saving numpy arrays into a file for later use\n",
    "\n",
    "### 1. Writing it into a csv file\n",
    "\n",
    "A **CSV (Comma-Separated Values) file** is a plain text format used to store **tabular data**, where each row represents a data entry and columns are separated by commas. It is widely used for data exchange between applications like spreadsheets, databases, and programming languages such as Python. CSV files are simple, lightweight, and easily readable by both humans and computers, making them a popular choice for storing structured data in a universally accessible format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "np.savetxt(\"data.csv\", data, delimiter=\",\", header=\"Population,Area,GDP,GDP_per_Capita\", comments='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Here is how you can print out the context of csv file in a terminal**\n",
    "the exclamation mark at the beginning tells Jupyter that this is a unix command to be executed in the Unix operating system the Jupyter Notebook is run on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -ltr\n",
    "!cat data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Here’s a simple Python script to print the contents of a CSV file when you don’t know what’s inside:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Open and read the CSV file\n",
    "with open(\"data.csv\", \"r\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    \n",
    "    # Print each row\n",
    "    for row in reader:\n",
    "        print(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting the numpy array back from the csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NumPy array from the CSV file (skipping the header)\n",
    "data_loaded = np.loadtxt(\"data.csv\", delimiter=\",\", skiprows=1)\n",
    "\n",
    "# Display the loaded NumPy array\n",
    "check_np(data_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another method\n",
    "\n",
    "data_loaded_v2 = np.genfromtxt(\"data.csv\", delimiter=\",\", skip_header=1)\n",
    "\n",
    "check_np(data_loaded_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Writing it into a (HDF5) h5 file\n",
    "\n",
    "An H5 file, or HDF5 (Hierarchical Data Format version 5), is a binary file format designed to store and organize large amounts of numerical data efficiently. It supports a hierarchical structure similar to a file system, allowing datasets, metadata, and groups to be stored within a single file. HDF5 is widely used in scientific computing, machine learning, and high-performance computing due to its ability to handle complex data structures and large-scale datasets efficiently. Libraries such as `h5py` in Python provide easy access for reading and writing HDF5 files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# Save to HDF5\n",
    "with h5py.File(\"data.h5\", \"w\") as hf:\n",
    "    hf.create_dataset(\"dataset\", data=data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -ltr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can get the numpy array back from an h5 file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the HDF5 file\n",
    "with h5py.File(\"data.h5\", \"r\") as hf:\n",
    "    mydata = np.array(hf[\"dataset\"])  # Read the dataset into a NumPy array\n",
    "\n",
    "# Print the retrieved data\n",
    "check_np(mydata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you don't know what is inside the h5 file, you can**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Open the HDF5 file in read mode\n",
    "with h5py.File(\"data.h5\", \"r\") as hf:\n",
    "    print(\"HDF5 file structure:\")\n",
    "    hf.visit(print)  # Lists all groups and datasets inside the file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"data.h5\", \"r\") as hf:\n",
    "    print(\"Datasets available:\", list(hf.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"data.h5\", \"r\") as hf:\n",
    "    for name in hf.keys():\n",
    "        dataset = hf[name]\n",
    "        print(f\"Dataset Name: {name}\")\n",
    "        print(f\" - Shape: {dataset.shape}\")\n",
    "        print(f\" - Data Type: {dataset.dtype}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Write the numpy array into a Pandas data frame and then save it as a `pickle` file\n",
    "\n",
    "A Pandas DataFrame is a two-dimensional, mutable data structure in Python that organizes data in a tabular format with labeled rows and columns. It provides powerful functionality for data manipulation, analysis, and visualization, making it a fundamental tool in data science and machine learning. DataFrames support operations such as filtering, grouping, merging, and handling missing values, and they can be created from various data sources, including CSV, Excel, SQL databases, and dictionaries.\n",
    "\n",
    "A Pickle file (`.pkl`) is a serialized binary format used to save Python objects, including Pandas DataFrames, lists, dictionaries, and custom objects. The `pickle` module in Python enables efficient storage and retrieval of objects, preserving their structure and data types. This format is useful for saving intermediate computations, caching results, and sharing complex objects across sessions without requiring reprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert NumPy array to Pandas DataFrame\n",
    "columns = [\"Population\", \"Area\", \"GDP\", \"GDP_per_Capita\"]\n",
    "rows = [\"CA\", \"NY\", \"FL\", \"TX\", \"WA\"]\n",
    "df = pd.DataFrame(data, columns=columns, index=rows)\n",
    "\n",
    "# Save as a Pickle file\n",
    "df.to_pickle(\"data.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Retrieving entries in dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"GDP\"])  # Get GDP column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( df.loc[\"CA\" , \"Population\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"CA\",\"Population\"] = 40.0\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.describe())  # Summary statistics (mean, min, max, std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading pandas dataframe from pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DataFrame from the pickle file\n",
    "df_v2 = pd.read_pickle(\"data.pkl\")\n",
    "\n",
    "# Display DataFrame\n",
    "print(df_v2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Comparison of CSV vs HDF5 vs Pandas/Pickle**\n",
    "\n",
    "| Feature            | **CSV (Comma-Separated Values)** | **HDF5 (Hierarchical Data Format)** | **Pandas/Pickle** |\n",
    "|--------------------|--------------------------------|------------------------------------|--------------------|\n",
    "| **File Type**      | Plain text                     | Binary (structured format)         | Binary (Python-specific) |\n",
    "| **Human-Readable?** | ✅ Yes (can be opened in Notepad, Excel) | ❌ No (binary format) | ❌ No (binary format) |\n",
    "| **Supports Structured Data?** | ❌ No (flat table only) | ✅ Yes (supports hierarchies & datasets) | ✅ Yes (Pandas DataFrame) |\n",
    "| **Supports Missing Data?** | ❌ No (must use placeholders like \"NA\") | ✅ Yes (native support) | ✅ Yes (native support) |\n",
    "| **Storage Efficiency** | ❌ Large file sizes (repetitive text) | ✅ Highly efficient for large data | ✅ Compact, but larger than HDF5 |\n",
    "| **Read/Write Speed** | ⏳ Slow (text parsing required) | ⚡ Fast (optimized for large datasets) | ⚡ Fast (stores DataFrame directly) |\n",
    "| **Supports Random Access?** | ❌ No (must read entire file) | ✅ Yes (supports chunk-based access) | ✅ Yes (row/column access) |\n",
    "| **Best For?** | Simple tabular data exchange | Large-scale numerical datasets | Storing Pandas DataFrames |\n",
    "| **Python Compatibility** | ✅ Supported (with `csv`, `pandas`, `numpy`) | ✅ Supported (with `h5py`, `pandas`) | ✅ Pandas-native (`to_pickle`, `read_pickle`) |\n",
    "| **Cross-Platform Use?** | ✅ Yes (universally supported) | ✅ Yes (widely used in HPC & machine learning) | ❌ No (Pickle is Python-specific) |\n",
    "| **Ideal Use Case** | Sharing small datasets | Storing large structured data | Fast loading of Pandas objects |\n",
    "\n",
    "---\n",
    "\n",
    "## **Summary: When to Use Each Format**\n",
    "- **Use CSV** if you need a simple, universally readable format for **small datasets**.\n",
    "- **Use HDF5** when dealing with **large, structured, or hierarchical datasets** and need **fast random access**.\n",
    "- **Use Pandas/Pickle** when working **within Python** and need to quickly **save/load a DataFrame** efficiently.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
